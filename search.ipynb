{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autokeras\n",
      "  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n",
      "     ---------------------------------------- 0.0/148.6 kB ? eta -:--:--\n",
      "     ------------------------------------ - 143.4/148.6 kB 8.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 148.6/148.6 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autokeras) (23.1)\n",
      "Collecting tensorflow>=2.8.0 (from autokeras)\n",
      "  Obtaining dependency information for tensorflow>=2.8.0 from https://files.pythonhosted.org/packages/80/6f/57d36f6507e432d7fc1956b2e9e8530c5c2d2bfcd8821bcbfae271cd6688/tensorflow-2.14.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.14.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting keras-tuner>=1.1.0 (from autokeras)\n",
      "  Obtaining dependency information for keras-tuner>=1.1.0 from https://files.pythonhosted.org/packages/ff/da/39a5389652e31b135d01833ff52a9cbb6538326150df4fc9f6f28cbfb700/keras_tuner-1.4.5-py3-none-any.whl.metadata\n",
      "  Downloading keras_tuner-1.4.5-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting keras-nlp>=0.4.0 (from autokeras)\n",
      "  Obtaining dependency information for keras-nlp>=0.4.0 from https://files.pythonhosted.org/packages/37/d4/dfd85606db811af2138e97fc480eb7ed709042dd96dd453868bede0929fe/keras_nlp-0.6.2-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autokeras) (2.0.3)\n",
      "Collecting keras-core (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for keras-core from https://files.pythonhosted.org/packages/95/f7/b8dcff937ea64f822f0d3fe8c6010793406b82d14467cd0e9eecea458a40/keras_core-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting absl-py (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras-nlp>=0.4.0->autokeras) (1.25.2)\n",
      "Requirement already satisfied: regex in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras-nlp>=0.4.0->autokeras) (2023.8.8)\n",
      "Collecting rich (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/be/2a/4e62ff633612f746f88618852a626bbe24226eba5e7ac90e91dcfd6a414e/rich-13.6.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting dm-tree (from keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl (101 kB)\n",
      "     ---------------------------------------- 0.0/101.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 101.3/101.3 kB 2.9 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of keras-nlp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting keras-nlp>=0.4.0 (from autokeras)\n",
      "  Obtaining dependency information for keras-nlp>=0.4.0 from https://files.pythonhosted.org/packages/13/fc/258d2a78faaacceeaab2be1a64fbf69f77bd56d55758cd4188db3b0f71e3/keras_nlp-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Obtaining dependency information for keras-nlp>=0.4.0 from https://files.pythonhosted.org/packages/b6/43/31296dfcc9ed404f4449f9d99d54471c04122d0a183cd5b15df1fd189492/keras_nlp-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Obtaining dependency information for keras-nlp>=0.4.0 from https://files.pythonhosted.org/packages/46/88/f8f6f5f6c2981f212b3a56d44e2523aee31b9d5cc3d8243b298068ed2aaa/keras_nlp-0.5.2-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.5.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading keras_nlp-0.5.1-py3-none-any.whl (527 kB)\n",
      "     ---------------------------------------- 0.0/527.1 kB ? eta -:--:--\n",
      "     ---------------------------- --------- 389.1/527.1 kB 8.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 527.1/527.1 kB 6.6 MB/s eta 0:00:00\n",
      "  Downloading keras_nlp-0.5.0-py3-none-any.whl (527 kB)\n",
      "     ---------------------------------------- 0.0/527.1 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 317.4/527.1 kB 9.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 527.1/527.1 kB 8.2 MB/s eta 0:00:00\n",
      "  Downloading keras_nlp-0.4.1-py3-none-any.whl (466 kB)\n",
      "     ---------------------------------------- 0.0/466.8 kB ? eta -:--:--\n",
      "     ---------------------- --------------- 276.5/466.8 kB 8.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 466.8/466.8 kB 5.9 MB/s eta 0:00:00\n",
      "  Downloading keras_nlp-0.4.0-py3-none-any.whl (337 kB)\n",
      "     ---------------------------------------- 0.0/337.5 kB ? eta -:--:--\n",
      "     ----------------------------------- - 327.7/337.5 kB 19.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- 337.5/337.5 kB 10.2 MB/s eta 0:00:00\n",
      "INFO: pip is still looking at multiple versions of keras-nlp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting autokeras\n",
      "  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n",
      "     ---------------------------------------- 0.0/162.4 kB ? eta -:--:--\n",
      "     ------------------------------------- 162.4/162.4 kB 10.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras-tuner>=1.1.0->autokeras) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner>=1.1.0->autokeras)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Collecting tensorflow-intel==2.14.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-intel==2.14.0 from https://files.pythonhosted.org/packages/ad/6e/1bfe367855dd87467564f7bf9fa14f3b17889988e79598bc37bf18f5ffb6/tensorflow_intel-2.14.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.14.0-cp311-cp311-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/b6/35/ed21094eb4d8acf31ccc7666a4d8701c1ce38f8d1fa3c7036f24416f6337/h5py-3.10.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes==0.2.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for ml-dtypes==0.2.0 from https://files.pythonhosted.org/packages/08/89/c727fde1a3d12586e0b8c01abf53754707d76beaa9987640e70807d4545f/ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/c2/59/f89c04923d68595d359f4cd7adbbdf5e5d791257945f8873d88b2fd1f979/protobuf-4.24.4-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.24.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for typing-extensions>=3.6.6 from https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for wrapt<1.15,>=1.11.0 from https://files.pythonhosted.org/packages/ba/7e/14113996bc6ee68eb987773b4139c87afd3ceff60e27e37648aa5eb2798a/wrapt-1.14.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     -------------- ------------------------- 0.5/1.5 MB 10.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.0/1.5 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 10.5 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/75/c5/fb3ed7495c73c0de58b08376a468a35bdb61b89ddfbdb96a37bceb54f959/grpcio-1.59.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.59.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.15,>=2.14 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorboard<2.15,>=2.14 from https://files.pythonhosted.org/packages/73/a2/66ed644f6ed1562e0285fcd959af17670ea313c8f331c46f79ee77187eb9/tensorboard-2.14.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.15,>=2.14.0 from https://files.pythonhosted.org/packages/d1/da/4f264c196325bb6e37a6285caec5b12a03def489b57cc1fdac02bb6272cd/tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.15,>=2.14.0 (from tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for keras<2.15,>=2.14.0 from https://files.pythonhosted.org/packages/fe/58/34d4d8f1aa11120c2d36d7ad27d0526164b1a8ae45990a2fede31d0e59bf/keras-2.14.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->autokeras) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->autokeras) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->autokeras) (2023.3)\n",
      "Collecting namex (from keras-core->keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2023.7.22)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for wheel<1.0,>=0.23.0 from https://files.pythonhosted.org/packages/b8/8b/31273bf66016be6ad22bb7345c37ff350276cfd46e389a0c2ac5da9d9073/wheel-0.41.2-py3-none-any.whl.metadata\n",
      "  Downloading wheel-0.41.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/39/7c/2e4fa55a99f83ef9ef229ac5d59c44ceb90e2d0145711590c0fa39669f32/google_auth-2.23.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/bb/c1/50caaec6cadc1c6adc8fe351e03bd646d6e4dd17f55fca0f4c8d7ea8d3e9/Markdown-3.5-py3-none-any.whl.metadata\n",
      "  Downloading Markdown-3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/da/61/6e9ff8258422d287eec718872fb71e05324356722ab658c8afda25f51539/tensorboard_data_server-0.7.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/b6/a5/54b01f663d60d5334f6c9c87c26274e94617a4fd463d812463626423b10d/werkzeug-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-3.0.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras-nlp>=0.4.0->autokeras) (2.16.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 181.3/181.3 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 0.0/83.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 83.9/83.9 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading keras_tuner-1.4.5-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.5 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 122.9/129.5 kB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 129.5/129.5 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.14.0-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.14.0-cp311-cp311-win_amd64.whl (284.2 MB)\n",
      "   ---------------------------------------- 0.0/284.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/284.2 MB 10.9 MB/s eta 0:00:27\n",
      "   ---------------------------------------- 1.0/284.2 MB 12.1 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 1.6/284.2 MB 12.8 MB/s eta 0:00:23\n",
      "   ---------------------------------------- 2.0/284.2 MB 11.7 MB/s eta 0:00:25\n",
      "   ---------------------------------------- 2.6/284.2 MB 11.9 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 3.1/284.2 MB 11.5 MB/s eta 0:00:25\n",
      "    --------------------------------------- 3.7/284.2 MB 11.9 MB/s eta 0:00:24\n",
      "    --------------------------------------- 4.2/284.2 MB 11.8 MB/s eta 0:00:24\n",
      "    --------------------------------------- 4.8/284.2 MB 11.8 MB/s eta 0:00:24\n",
      "    --------------------------------------- 5.4/284.2 MB 11.8 MB/s eta 0:00:24\n",
      "    --------------------------------------- 5.8/284.2 MB 11.1 MB/s eta 0:00:26\n",
      "    --------------------------------------- 6.5/284.2 MB 11.8 MB/s eta 0:00:24\n",
      "    --------------------------------------- 6.9/284.2 MB 11.6 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 7.4/284.2 MB 11.5 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 7.8/284.2 MB 11.3 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 8.0/284.2 MB 11.2 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 8.6/284.2 MB 11.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 9.2/284.2 MB 11.1 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 9.8/284.2 MB 11.2 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 10.1/284.2 MB 11.2 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 10.1/284.2 MB 11.2 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 10.6/284.2 MB 10.4 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 11.1/284.2 MB 10.6 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 11.7/284.2 MB 10.4 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 12.2/284.2 MB 10.6 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 12.8/284.2 MB 10.6 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 13.4/284.2 MB 10.7 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 13.9/284.2 MB 10.6 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 14.5/284.2 MB 10.7 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 15.1/284.2 MB 10.6 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 15.6/284.2 MB 10.6 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 16.3/284.2 MB 10.6 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 16.8/284.2 MB 10.7 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 17.3/284.2 MB 10.7 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 17.9/284.2 MB 10.9 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 18.5/284.2 MB 11.3 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 19.0/284.2 MB 11.3 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 19.6/284.2 MB 11.3 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 20.2/284.2 MB 11.3 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 20.7/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 20.8/284.2 MB 11.9 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 20.8/284.2 MB 11.9 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 22.3/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 22.9/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 23.5/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 24.0/284.2 MB 11.9 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 24.5/284.2 MB 11.9 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 25.2/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 25.8/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 26.4/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 26.9/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 27.5/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 28.1/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 28.7/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 29.2/284.2 MB 12.1 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 29.7/284.2 MB 12.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 30.2/284.2 MB 11.9 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 30.7/284.2 MB 11.9 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 31.3/284.2 MB 13.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 31.8/284.2 MB 12.8 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 32.4/284.2 MB 12.1 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 32.9/284.2 MB 11.9 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 33.5/284.2 MB 11.9 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 34.0/284.2 MB 11.9 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 34.6/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 35.2/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 35.8/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 36.4/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 36.9/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 37.6/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 38.1/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 38.6/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 39.2/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 39.8/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 40.3/284.2 MB 12.1 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 40.9/284.2 MB 12.1 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 41.5/284.2 MB 12.1 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 41.8/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 42.4/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 42.9/284.2 MB 11.9 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 43.4/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 44.1/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 44.7/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 45.3/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 45.8/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 46.4/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 46.9/284.2 MB 11.9 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 47.4/284.2 MB 11.9 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 48.0/284.2 MB 11.9 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 48.6/284.2 MB 11.9 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 49.2/284.2 MB 11.9 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 49.8/284.2 MB 11.9 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 50.1/284.2 MB 11.7 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 50.9/284.2 MB 11.9 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 51.5/284.2 MB 12.1 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 52.1/284.2 MB 12.4 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 52.7/284.2 MB 12.4 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 53.2/284.2 MB 12.4 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 53.8/284.2 MB 12.4 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 54.4/284.2 MB 12.3 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 54.9/284.2 MB 12.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 55.4/284.2 MB 12.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 56.1/284.2 MB 12.4 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 56.7/284.2 MB 12.6 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 57.3/284.2 MB 12.6 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 57.9/284.2 MB 12.8 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 58.4/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 59.0/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 59.5/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 60.1/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 60.7/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 61.2/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 61.9/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 62.4/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 63.1/284.2 MB 12.6 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 63.6/284.2 MB 12.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 64.1/284.2 MB 12.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 64.4/284.2 MB 12.1 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 65.2/284.2 MB 12.3 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 65.8/284.2 MB 12.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 66.3/284.2 MB 12.4 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 66.8/284.2 MB 12.1 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 67.3/284.2 MB 11.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 67.8/284.2 MB 11.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 68.2/284.2 MB 11.7 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 68.7/284.2 MB 11.7 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 69.2/284.2 MB 11.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 69.8/284.2 MB 11.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 70.2/284.2 MB 11.3 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 70.7/284.2 MB 11.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 71.1/284.2 MB 11.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 71.6/284.2 MB 11.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 72.2/284.2 MB 10.9 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 72.7/284.2 MB 10.9 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 73.2/284.2 MB 10.7 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 73.8/284.2 MB 10.7 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 74.3/284.2 MB 10.6 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 74.9/284.2 MB 11.1 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 75.6/284.2 MB 10.9 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 76.1/284.2 MB 11.1 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 76.8/284.2 MB 11.1 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 77.3/284.2 MB 11.3 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 77.8/284.2 MB 11.3 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 78.5/284.2 MB 11.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 79.0/284.2 MB 11.7 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 79.5/284.2 MB 11.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 80.0/284.2 MB 11.7 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 80.6/284.2 MB 11.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 80.6/284.2 MB 11.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 80.7/284.2 MB 10.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 81.0/284.2 MB 10.6 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 81.2/284.2 MB 10.4 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 81.7/284.2 MB 10.2 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 82.1/284.2 MB 10.4 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 82.8/284.2 MB 10.4 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 83.3/284.2 MB 10.6 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 83.3/284.2 MB 9.9 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 83.9/284.2 MB 9.9 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 84.4/284.2 MB 10.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 84.9/284.2 MB 9.9 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 85.5/284.2 MB 9.8 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 86.0/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 86.6/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 87.3/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 87.8/284.2 MB 10.1 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 88.4/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 88.9/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 89.5/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 90.0/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 90.5/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 91.1/284.2 MB 10.9 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 91.7/284.2 MB 11.5 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 92.1/284.2 MB 11.3 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 92.2/284.2 MB 11.3 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 92.2/284.2 MB 11.3 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 93.8/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 94.4/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 95.0/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 95.5/284.2 MB 11.9 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 96.1/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 96.7/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 97.3/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 97.9/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 98.4/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 99.0/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 99.6/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 100.2/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 100.8/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 100.9/284.2 MB 12.1 MB/s eta 0:00:16\n",
      "   ------------- ------------------------- 101.6/284.2 MB 11.9 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 102.2/284.2 MB 11.9 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 102.7/284.2 MB 13.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 103.1/284.2 MB 12.6 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 103.7/284.2 MB 11.9 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 104.2/284.2 MB 11.7 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 104.7/284.2 MB 11.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 105.2/284.2 MB 11.7 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 105.9/284.2 MB 11.7 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 106.5/284.2 MB 11.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 107.0/284.2 MB 11.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 107.5/284.2 MB 11.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 108.1/284.2 MB 11.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 108.7/284.2 MB 11.7 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 109.1/284.2 MB 11.7 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 109.8/284.2 MB 11.3 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 110.3/284.2 MB 11.5 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 110.9/284.2 MB 11.3 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 111.4/284.2 MB 11.7 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 111.8/284.2 MB 11.5 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 112.0/284.2 MB 11.3 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 112.1/284.2 MB 10.9 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 112.3/284.2 MB 10.4 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 112.5/284.2 MB 10.1 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 112.6/284.2 MB 9.8 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 112.9/284.2 MB 9.5 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 113.1/284.2 MB 9.4 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 113.3/284.2 MB 9.1 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 113.6/284.2 MB 9.0 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 113.8/284.2 MB 8.7 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 114.1/284.2 MB 8.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 114.3/284.2 MB 8.4 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 114.6/284.2 MB 8.3 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 114.9/284.2 MB 8.2 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 115.2/284.2 MB 8.1 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 115.6/284.2 MB 7.9 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 115.9/284.2 MB 7.8 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 116.1/284.2 MB 7.6 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 116.2/284.2 MB 7.4 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 116.4/284.2 MB 7.2 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 116.7/284.2 MB 7.1 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 116.9/284.2 MB 7.0 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 117.2/284.2 MB 7.0 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 117.4/284.2 MB 6.8 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 117.6/284.2 MB 6.6 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 117.7/284.2 MB 6.5 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 117.9/284.2 MB 6.4 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 118.1/284.2 MB 6.2 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 118.3/284.2 MB 6.1 MB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 118.4/284.2 MB 6.0 MB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 118.6/284.2 MB 5.9 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 118.8/284.2 MB 5.8 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 118.9/284.2 MB 5.7 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 119.1/284.2 MB 5.6 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 119.3/284.2 MB 5.5 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 119.4/284.2 MB 5.4 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 119.6/284.2 MB 5.3 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 119.8/284.2 MB 5.2 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 120.1/284.2 MB 5.2 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 120.3/284.2 MB 5.1 MB/s eta 0:00:33\n",
      "   ---------------- ----------------------- 120.5/284.2 MB 5.0 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 120.9/284.2 MB 5.0 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 121.0/284.2 MB 4.9 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 121.2/284.2 MB 4.9 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 121.4/284.2 MB 4.8 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 121.6/284.2 MB 4.7 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 121.8/284.2 MB 4.6 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 121.9/284.2 MB 4.6 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 122.1/284.2 MB 4.6 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 122.3/284.2 MB 4.6 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 122.5/284.2 MB 4.6 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 122.7/284.2 MB 4.6 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 122.8/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 123.1/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 123.3/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 123.7/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 123.9/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 124.0/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 124.2/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 124.4/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 124.7/284.2 MB 4.5 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 124.8/284.2 MB 4.5 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 125.0/284.2 MB 4.5 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 125.1/284.2 MB 4.4 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 125.7/284.2 MB 4.5 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 126.2/284.2 MB 4.6 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 126.8/284.2 MB 4.8 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 127.4/284.2 MB 4.9 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 128.0/284.2 MB 5.2 MB/s eta 0:00:30\n",
      "   ------------------ --------------------- 128.6/284.2 MB 5.6 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 129.2/284.2 MB 5.9 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 129.8/284.2 MB 6.3 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 130.4/284.2 MB 6.7 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 130.9/284.2 MB 6.8 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 131.4/284.2 MB 7.1 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 131.9/284.2 MB 7.4 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 132.3/284.2 MB 7.7 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 132.7/284.2 MB 8.2 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 133.1/284.2 MB 8.6 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 133.6/284.2 MB 8.8 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 134.1/284.2 MB 9.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 134.5/284.2 MB 9.8 MB/s eta 0:00:16\n",
      "   ------------------ -------------------- 135.0/284.2 MB 10.4 MB/s eta 0:00:15\n",
      "   ------------------ -------------------- 135.5/284.2 MB 11.1 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 135.9/284.2 MB 11.1 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 136.4/284.2 MB 10.9 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 136.8/284.2 MB 10.7 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 137.2/284.2 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 137.7/284.2 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 138.2/284.2 MB 10.4 MB/s eta 0:00:15\n",
      "   ------------------- ------------------- 138.7/284.2 MB 10.4 MB/s eta 0:00:15\n",
      "   ------------------- ------------------- 139.1/284.2 MB 10.2 MB/s eta 0:00:15\n",
      "   ------------------- ------------------- 139.7/284.2 MB 10.2 MB/s eta 0:00:15\n",
      "   ------------------- ------------------- 140.1/284.2 MB 10.1 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 140.6/284.2 MB 9.9 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 141.0/284.2 MB 9.9 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 141.6/284.2 MB 9.9 MB/s eta 0:00:15\n",
      "   ------------------- ------------------- 142.2/284.2 MB 10.2 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 142.8/284.2 MB 10.2 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 143.2/284.2 MB 10.2 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 143.8/284.2 MB 10.4 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 144.4/284.2 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 145.0/284.2 MB 10.7 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 145.6/284.2 MB 10.7 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 146.1/284.2 MB 11.1 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 146.8/284.2 MB 11.1 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 147.3/284.2 MB 11.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 147.7/284.2 MB 11.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 148.3/284.2 MB 11.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 148.9/284.2 MB 11.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 149.4/284.2 MB 11.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 150.0/284.2 MB 11.7 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 150.5/284.2 MB 11.9 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 151.1/284.2 MB 11.9 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 151.7/284.2 MB 11.9 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 152.2/284.2 MB 11.9 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 152.9/284.2 MB 12.1 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 153.1/284.2 MB 11.9 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 153.6/284.2 MB 11.9 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 154.2/284.2 MB 11.9 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 154.7/284.2 MB 11.9 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 154.8/284.2 MB 11.7 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 154.9/284.2 MB 10.9 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 155.3/284.2 MB 10.7 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 155.9/284.2 MB 10.6 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 156.4/284.2 MB 10.7 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 157.0/284.2 MB 10.6 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 157.4/284.2 MB 10.6 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 157.8/284.2 MB 10.4 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 158.2/284.2 MB 10.4 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 158.8/284.2 MB 10.2 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 159.2/284.2 MB 10.1 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 159.9/284.2 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------------- ---------------- 160.4/284.2 MB 10.1 MB/s eta 0:00:13\n",
      "   ---------------------- ---------------- 161.0/284.2 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------------- ---------------- 161.3/284.2 MB 10.2 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 161.5/284.2 MB 9.8 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 162.1/284.2 MB 9.8 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 162.6/284.2 MB 9.6 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 163.1/284.2 MB 9.5 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 163.5/284.2 MB 9.6 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 163.8/284.2 MB 9.6 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 164.3/284.2 MB 9.5 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 164.8/284.2 MB 9.5 MB/s eta 0:00:13\n",
      "   ---------------------- ---------------- 165.3/284.2 MB 10.4 MB/s eta 0:00:12\n",
      "   ---------------------- ---------------- 165.8/284.2 MB 10.2 MB/s eta 0:00:12\n",
      "   ---------------------- ---------------- 166.2/284.2 MB 10.2 MB/s eta 0:00:12\n",
      "   ---------------------- ---------------- 166.5/284.2 MB 10.1 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 167.0/284.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 167.3/284.2 MB 9.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 167.8/284.2 MB 9.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 168.2/284.2 MB 9.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 168.6/284.2 MB 9.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 168.9/284.2 MB 9.5 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 169.4/284.2 MB 9.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 169.8/284.2 MB 9.5 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 170.3/284.2 MB 9.4 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 170.7/284.2 MB 9.2 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 171.0/284.2 MB 9.2 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 171.6/284.2 MB 9.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 172.0/284.2 MB 9.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 172.6/284.2 MB 9.4 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 173.1/284.2 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 173.6/284.2 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 174.0/284.2 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 174.6/284.2 MB 9.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 175.0/284.2 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 175.5/284.2 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 176.1/284.2 MB 9.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 176.6/284.2 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 177.2/284.2 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 177.7/284.2 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 178.3/284.2 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 178.9/284.2 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 179.4/284.2 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 179.9/284.2 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 180.3/284.2 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 180.8/284.2 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 181.5/284.2 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 181.9/284.2 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 182.5/284.2 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 182.9/284.2 MB 11.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 183.4/284.2 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 183.9/284.2 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 184.4/284.2 MB 11.1 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 184.9/284.2 MB 11.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 185.4/284.2 MB 11.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 186.0/284.2 MB 11.5 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 186.5/284.2 MB 11.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 187.1/284.2 MB 11.5 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 187.6/284.2 MB 11.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 187.9/284.2 MB 11.1 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 188.4/284.2 MB 10.9 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 188.8/284.2 MB 10.7 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 189.2/284.2 MB 10.7 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 189.6/284.2 MB 10.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 190.0/284.2 MB 10.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------ 190.3/284.2 MB 10.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------ 190.7/284.2 MB 10.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------ 191.1/284.2 MB 10.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 191.4/284.2 MB 9.9 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 191.7/284.2 MB 9.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 192.0/284.2 MB 9.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 192.3/284.2 MB 9.2 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 192.4/284.2 MB 9.1 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 192.7/284.2 MB 8.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 193.0/284.2 MB 8.6 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 193.5/284.2 MB 8.7 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 193.9/284.2 MB 8.6 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 194.4/284.2 MB 8.7 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 194.8/284.2 MB 8.6 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 195.2/284.2 MB 8.6 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 195.7/284.2 MB 8.6 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 196.1/284.2 MB 8.5 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 196.5/284.2 MB 8.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 197.0/284.2 MB 8.3 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 197.5/284.2 MB 8.3 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 197.9/284.2 MB 8.3 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 198.4/284.2 MB 8.4 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 198.9/284.2 MB 8.4 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 199.3/284.2 MB 8.4 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 199.8/284.2 MB 8.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 200.4/284.2 MB 8.5 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 200.9/284.2 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 201.3/284.2 MB 8.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 201.8/284.2 MB 9.1 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 202.3/284.2 MB 9.2 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 202.9/284.2 MB 10.1 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 203.3/284.2 MB 10.1 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 203.8/284.2 MB 10.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 204.3/284.2 MB 10.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 204.7/284.2 MB 10.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 205.2/284.2 MB 10.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 205.6/284.2 MB 10.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 206.1/284.2 MB 10.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 206.6/284.2 MB 10.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 207.1/284.2 MB 10.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 207.6/284.2 MB 10.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 208.1/284.2 MB 10.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 208.6/284.2 MB 10.6 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 209.1/284.2 MB 10.6 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 209.6/284.2 MB 10.6 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 210.1/284.2 MB 10.6 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 210.5/284.2 MB 10.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 211.0/284.2 MB 10.4 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 211.4/284.2 MB 10.2 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 211.9/284.2 MB 10.2 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 212.3/284.2 MB 10.2 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 212.8/284.2 MB 10.2 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 213.0/284.2 MB 10.2 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 213.0/284.2 MB 10.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 213.5/284.2 MB 9.5 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 214.6/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 215.0/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 215.5/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 215.9/284.2 MB 10.2 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 216.5/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 217.0/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 217.4/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 218.1/284.2 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 218.6/284.2 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 219.0/284.2 MB 10.2 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 219.7/284.2 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 220.2/284.2 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 220.7/284.2 MB 10.6 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 221.0/284.2 MB 10.4 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 221.3/284.2 MB 10.2 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 221.7/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 222.1/284.2 MB 10.1 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 222.4/284.2 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 222.9/284.2 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 223.3/284.2 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 223.8/284.2 MB 10.6 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 224.3/284.2 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 224.8/284.2 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 225.4/284.2 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 225.9/284.2 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 226.4/284.2 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 226.8/284.2 MB 10.1 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 227.3/284.2 MB 10.2 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 227.7/284.2 MB 10.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 227.9/284.2 MB 9.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 228.4/284.2 MB 9.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 228.8/284.2 MB 9.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 229.0/284.2 MB 8.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 229.5/284.2 MB 8.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 230.5/284.2 MB 8.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 231.1/284.2 MB 8.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 231.9/284.2 MB 9.5 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 232.7/284.2 MB 9.5 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 233.1/284.2 MB 8.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 233.4/284.2 MB 8.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 233.6/284.2 MB 8.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 233.9/284.2 MB 8.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 234.3/284.2 MB 7.4 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 234.6/284.2 MB 7.4 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 234.8/284.2 MB 7.2 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 234.8/284.2 MB 7.0 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 235.0/284.2 MB 6.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 235.2/284.2 MB 6.4 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 235.3/284.2 MB 6.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 235.5/284.2 MB 6.1 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 235.7/284.2 MB 6.0 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 235.9/284.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 236.3/284.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 236.3/284.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 236.3/284.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 236.3/284.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 236.3/284.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 236.5/284.2 MB 4.8 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 236.7/284.2 MB 4.7 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 237.1/284.2 MB 4.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 237.7/284.2 MB 4.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 238.0/284.2 MB 4.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 238.3/284.2 MB 4.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 238.9/284.2 MB 4.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 239.1/284.2 MB 4.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 239.3/284.2 MB 4.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 239.5/284.2 MB 4.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 239.9/284.2 MB 4.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 240.1/284.2 MB 4.5 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 240.5/284.2 MB 4.5 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 241.0/284.2 MB 4.4 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 241.3/284.2 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 241.6/284.2 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 241.8/284.2 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 242.0/284.2 MB 4.1 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 242.2/284.2 MB 4.1 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 242.4/284.2 MB 4.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 242.6/284.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 242.9/284.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 243.1/284.2 MB 3.9 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 243.4/284.2 MB 4.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 243.7/284.2 MB 4.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 243.8/284.2 MB 4.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 244.2/284.2 MB 4.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 244.4/284.2 MB 4.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 244.7/284.2 MB 4.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 245.6/284.2 MB 4.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 245.9/284.2 MB 4.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 246.4/284.2 MB 4.8 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 246.9/284.2 MB 5.8 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 247.5/284.2 MB 6.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 248.0/284.2 MB 6.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 248.5/284.2 MB 6.2 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 249.0/284.2 MB 6.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 249.6/284.2 MB 6.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 250.1/284.2 MB 6.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 250.5/284.2 MB 7.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 251.1/284.2 MB 7.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 251.6/284.2 MB 7.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 252.2/284.2 MB 7.9 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 252.7/284.2 MB 8.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 253.3/284.2 MB 9.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 253.8/284.2 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 254.4/284.2 MB 10.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 254.9/284.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 255.5/284.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 256.1/284.2 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 256.6/284.2 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 257.3/284.2 MB 11.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 257.8/284.2 MB 11.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 258.4/284.2 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 258.9/284.2 MB 12.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 259.5/284.2 MB 12.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 260.2/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 260.7/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 261.2/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 261.7/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 262.3/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 262.8/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 263.5/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 264.1/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 264.7/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 265.2/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 265.8/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 266.4/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 267.0/284.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 267.6/284.2 MB 12.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 268.3/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 268.9/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 269.5/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 270.1/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 270.7/284.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 271.3/284.2 MB 12.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 271.8/284.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 272.4/284.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 272.9/284.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 273.6/284.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 274.1/284.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 274.8/284.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 275.4/284.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 276.0/284.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 276.5/284.2 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  277.1/284.2 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  277.3/284.2 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  277.6/284.2 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  277.8/284.2 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  279.1/284.2 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  279.7/284.2 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  280.4/284.2 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  281.0/284.2 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  281.4/284.2 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  282.1/284.2 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  282.6/284.2 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  283.2/284.2 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  283.8/284.2 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  284.2/284.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 284.2/284.2 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl (938 kB)\n",
      "   ---------------------------------------- 0.0/938.7 kB ? eta -:--:--\n",
      "   ------------------------ -------------- 593.9/938.7 kB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 938.7/938.7 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
      "   ---------------------------------------- 0.0/950.8 kB ? eta -:--:--\n",
      "   -------------------------- ------------ 655.4/950.8 kB 13.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 950.8/950.8 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.2/130.2 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.59.0-cp311-cp311-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/3.7 MB 15.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.0/3.7 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.7/3.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.2/3.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.6/3.7 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.1/3.7 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.4/3.7 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.4/2.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.6/1.7 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/24.4 MB 8.7 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.1/24.4 MB 11.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.7/24.4 MB 11.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.2/24.4 MB 11.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.7/24.4 MB 11.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 12.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.0/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.6/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.1/24.4 MB 12.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 5.7/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.2/24.4 MB 12.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 6.9/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.5/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.0/24.4 MB 12.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.6/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.1/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.8/24.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 9.9/24.4 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 9.9/24.4 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.5/24.4 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.0/24.4 MB 12.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.6/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.2/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.8/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.3/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 14.9/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.4/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.1/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.7/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.3/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.9/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.4/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.1/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.6/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.2/24.4 MB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.8/24.4 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.3/24.4 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.9/24.4 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.5/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.0/24.4 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.2/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.24.4-cp310-abi3-win_amd64.whl (430 kB)\n",
      "   ---------------------------------------- 0.0/430.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 430.5/430.5 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.1/5.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.7/5.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.2/5.5 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.8/5.5 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.8/5.5 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.7 kB ? eta -:--:--\n",
      "   --------------------------------------  440.3/440.7 kB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 440.7/440.7 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading wrapt-1.14.1-cp311-cp311-win_amd64.whl (35 kB)\n",
      "Downloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/239.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 239.8/239.8 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/182.3 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 61.4/182.3 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 182.3/182.3 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.7/101.7 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.0-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 226.6/226.6 kB 7.0 MB/s eta 0:00:00\n",
      "Using cached wheel-0.41.2-py3-none-any.whl (64 kB)\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: namex, libclang, kt-legacy, flatbuffers, dm-tree, wrapt, wheel, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, mdurl, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown-it-py, astunparse, rich, google-auth, keras-core, google-auth-oauthlib, tensorboard, keras-tuner, tensorflow-intel, tensorflow, autokeras\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 autokeras-1.0.20 cachetools-5.3.1 dm-tree-0.1.8 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.10.0 keras-2.14.0 keras-core-0.1.7 keras-tuner-1.4.5 kt-legacy-1.0.5 libclang-16.0.6 markdown-3.5 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.2.0 namex-0.0.7 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rich-13.6.0 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-intel-2.14.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.8.0 werkzeug-3.0.0 wheel-0.41.2 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "!pip install autokeras\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'C:\\Users\\Student\\OneDrive - Florida International University\\Desktop\\Capstone Project\\Tanvir data\\BRCA-subtypes-combined-tumor-samples-only-gdc-tcga-refined.csv'\n",
    "BRCA = pd.read_csv(path)\n",
    "path = 'C:\\Users\\Student\\OneDrive - Florida International University\\Desktop\\Capstone Project\\Tanvir data\\GDC_rnaseq_fpkm_unstranded_v4.csv'\n",
    "GDC = pd.read_csv(path)\n",
    "path = 'C:\\Users\\Student\\OneDrive - Florida International University\\Desktop\\Capstone Project\\Tanvir data\\MUT_combined_v4.csv'\n",
    "MUT = pd.read_csv(path)\n",
    "path = 'C:\\Users\\Student\\OneDrive - Florida International University\\Desktop\\Capstone Project\\Tanvir data\\cnv_segment_gene_centric_v4.csv'\n",
    "CNV = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>Subtype_mRNA_PANCAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-3C-AAAU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-3C-AALI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Her2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-3C-AALJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-3C-AALK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-4H-AAAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SampleID  A1BG  A1CF  A2M  A2ML1  A4GALT  A4GNT  AAAS  AACS  AADAC  \\\n",
       "0  TCGA-3C-AAAU     0     0    0      1       0      0     0     0      0   \n",
       "1  TCGA-3C-AALI     0     0    0      0       0      0     0     0      0   \n",
       "2  TCGA-3C-AALJ     0     0    0      0       0      0     0     0      0   \n",
       "3  TCGA-3C-AALK     0     0    0      0       0      0     0     0      0   \n",
       "4  TCGA-4H-AAAK     0     0    0      0       0      0     0     0      0   \n",
       "\n",
       "   ...  ZWILCH  ZWINT  ZXDA  ZXDB  ZXDC  ZYG11B  ZYX  ZZEF1  ZZZ3  \\\n",
       "0  ...       0      0     0     0     0       0    0      0     0   \n",
       "1  ...       0      0     0     0     0       0    0      0     0   \n",
       "2  ...       0      0     0     0     0       0    0      0     0   \n",
       "3  ...       0      0     0     0     0       0    0      0     0   \n",
       "4  ...       0      0     0     0     0       0    0      0     0   \n",
       "\n",
       "   Subtype_mRNA_PANCAN  \n",
       "0                 LumA  \n",
       "1                 Her2  \n",
       "2                 LumB  \n",
       "3                 LumA  \n",
       "4                 LumA  \n",
       "\n",
       "[5 rows x 16664 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MUT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n",
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_12768\\4013134705.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  MUT[f'padding_{i}'] = 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(238):\n",
    "    MUT[f'padding_{i}'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/f1/7d/2e562207176a5dcdad513085670674bb11ffaf37e1393eacb6d7fb502481/scikit_learn-1.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.5.0 from https://files.pythonhosted.org/packages/81/d7/d2537d51efb692d0c411e64267ba349e7668d40f5bc73cefe78ccd650dcd/scipy-1.11.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.11.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.4/60.4 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.1-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.2 MB 9.0 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.2/9.2 MB 9.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.3/9.2 MB 2.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/9.2 MB 3.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/9.2 MB 4.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.2/9.2 MB 4.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.5/9.2 MB 4.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.0/9.2 MB 5.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.5/9.2 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/9.2 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.2/9.2 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.6/9.2 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.1/9.2 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.5/9.2 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.0/9.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.4/9.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.8/9.2 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.2/9.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.2 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.3/9.2 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.8/9.2 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.3/9.2 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.8/9.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.2/302.2 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.3-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/44.1 MB 11.1 MB/s eta 0:00:04\n",
      "    --------------------------------------- 1.0/44.1 MB 10.8 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.5/44.1 MB 10.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.9/44.1 MB 10.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.3/44.1 MB 10.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 2.8/44.1 MB 9.9 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.2/44.1 MB 9.9 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.7/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 4.2/44.1 MB 10.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/44.1 MB 10.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.2/44.1 MB 10.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.7/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.1/44.1 MB 10.3 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.6/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.0/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.5/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.0/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.4/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.9/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.3/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.7/44.1 MB 10.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.2/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.7/44.1 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.1/44.1 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.7/44.1 MB 9.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.2/44.1 MB 10.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.8/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.3/44.1 MB 10.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 13.9/44.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.4/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.8/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 15.4/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 15.9/44.1 MB 10.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.5/44.1 MB 10.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.1/44.1 MB 10.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.6/44.1 MB 10.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.0/44.1 MB 10.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.4/44.1 MB 10.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 18.9/44.1 MB 10.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.3/44.1 MB 10.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.6/44.1 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.0/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.4/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.9/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.4/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.0/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.5/44.1 MB 10.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.0/44.1 MB 10.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.5/44.1 MB 10.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.0/44.1 MB 10.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 24.5/44.1 MB 10.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.1/44.1 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 25.7/44.1 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.2/44.1 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 26.8/44.1 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.4/44.1 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.0/44.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.5/44.1 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.1/44.1 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.7/44.1 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.3/44.1 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 30.9/44.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.5/44.1 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.0/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.6/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.6/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 34.2/44.1 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 34.7/44.1 MB 12.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.3/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.9/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.4/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.9/44.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.5/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 38.6/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.2/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.8/44.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.2/44.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.8/44.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.3/44.1 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.5/44.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.0/44.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.6/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 8.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.1 scipy-1.11.3 threadpoolctl-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "df=MUT\n",
    "!pip install -U scikit-learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming your class labels are in a Series named 'Subtype_mRNA_PANCAN'\n",
    "label_encoder = LabelEncoder()\n",
    "integer_labels = label_encoder.fit_transform(df['Subtype_mRNA_PANCAN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.drop('Subtype_mRNA_PANCAN', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an empty list to store the ndarray representations of the plots\n",
    "plots_as_arrays = []\n",
    "\n",
    "for i in range(969):\n",
    "    df.loc[i]\n",
    "    data = df.loc[i].values\n",
    "    data = np.array(data)\n",
    "    grid = np.reshape(data, (130, 130))\n",
    "\n",
    "    # Append the grid (plot) as a NumPy array to the list\n",
    "    plots_as_arrays.append(grid)\n",
    "\n",
    "# Save the list of arrays as a NumPy ndarray\n",
    "plots_as_ndarray = np.array(plots_as_arrays)\n",
    "\n",
    "# Save the NumPy ndarray to a file\n",
    "np.save('plots_as_arrays.npy', plots_as_ndarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_as_ndarray = plots_as_ndarray.astype('float32') / 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=plots_as_ndarray\n",
    "y=integer_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'gray_images' contains your grayscale image data with shape (969, 130, 130)  # Replace with your actual data\n",
    "X_rgb = np.empty((969, 130, 130, 3))\n",
    "\n",
    "# Fill all three RGB channels with the grayscale values\n",
    "X_rgb[..., 0] = X\n",
    "X_rgb[..., 1] = X\n",
    "X_rgb[..., 2] = X\n",
    "\n",
    "# Now, 'rgb_images' contains the grayscale images in RGB format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 03m 03s]\n",
      "val_loss: 32422.5546875\n",
      "\n",
      "Best val_loss So Far: 32422.5546875\n",
      "Total elapsed time: 00h 03m 03s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0                 |0                 |image_augmentation_1/translation_factor\n",
      "0                 |0                 |image_augmentation_1/rotation_factor\n",
      "0                 |0                 |image_augmentation_1/zoom_factor\n",
      "0                 |0                 |image_augmentation_1/contrast_factor\n",
      "False             |False             |res_net_block_1/pretrained\n",
      "resnet152_v2      |resnet50          |res_net_block_1/version\n",
      "False             |False             |res_net_block_1/imagenet_size\n",
      "flatten           |flatten           |classification_head_1/spatial_reduction_1/reduction_type\n",
      "0.25              |0.25              |classification_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m output_node \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mClassificationHead()(output_node)\n\u001b[0;32m      6\u001b[0m clf \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mAutoModel(\n\u001b[0;32m      7\u001b[0m     inputs\u001b[39m=\u001b[39minput_node, outputs\u001b[39m=\u001b[39moutput_node, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_trials\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\auto_model.py:292\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m validation_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m validation_split:\n\u001b[0;32m    288\u001b[0m     dataset, validation_data \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39msplit_dataset(\n\u001b[0;32m    289\u001b[0m         dataset, validation_split\n\u001b[0;32m    290\u001b[0m     )\n\u001b[1;32m--> 292\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49msearch(\n\u001b[0;32m    293\u001b[0m     x\u001b[39m=\u001b[39;49mdataset,\n\u001b[0;32m    294\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    295\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    296\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m    297\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    298\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    299\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    300\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\engine\\tuner.py:193\u001b[0m, in \u001b[0;36mAutoTuner.search\u001b[1;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[1;32m--> 193\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msearch(\n\u001b[0;32m    194\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, callbacks\u001b[39m=\u001b[39;49mnew_callbacks, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs\n\u001b[0;32m    195\u001b[0m )\n\u001b[0;32m    197\u001b[0m \u001b[39m# Train the best model use validation data.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# Train the best model with enough number of epochs.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m validation_split \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m early_stopping_inserted:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 233\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    272\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    274\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    275\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 238\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    240\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    241\u001b[0m     ):\n\u001b[0;32m    242\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    243\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    246\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    254\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\engine\\tuner.py:101\u001b[0m, in \u001b[0;36mAutoTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m pipeline\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_path(trial\u001b[39m.\u001b[39mtrial_id))\n\u001b[0;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt(model, kwargs[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 101\u001b[0m _, history \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mfit_with_adaptive_batch_size(\n\u001b[0;32m    102\u001b[0m     model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbatch_size, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\utils\\utils.py:88\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size\u001b[1;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m---> 88\u001b[0m     history \u001b[39m=\u001b[39m run_with_adaptive_batch_size(\n\u001b[0;32m     89\u001b[0m         batch_size, \u001b[39mlambda\u001b[39;49;00m \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs: model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs\n\u001b[0;32m     90\u001b[0m     )\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\utils\\utils.py:101\u001b[0m, in \u001b[0;36mrun_with_adaptive_batch_size\u001b[1;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mwhile\u001b[39;00m batch_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m         history \u001b[39m=\u001b[39m func(x\u001b[39m=\u001b[39;49mx, validation_data\u001b[39m=\u001b[39;49mvalidation_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[0;32m    102\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[39mexcept\u001b[39;00m tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mResourceExhaustedError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\utils\\utils.py:89\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m     88\u001b[0m     history \u001b[39m=\u001b[39m run_with_adaptive_batch_size(\n\u001b[1;32m---> 89\u001b[0m         batch_size, \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs\n\u001b[0;32m     90\u001b[0m     )\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:887\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    885\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 887\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    888\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    889\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    890\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    891\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    690\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    691\u001b[0m     tracing_compilation\u001b[39m.\u001b[39mScopeType\u001b[39m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    692\u001b[0m )\n\u001b[0;32m    693\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mtrace_function(\n\u001b[0;32m    695\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[0;32m    696\u001b[0m )\n\u001b[0;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[0;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[0;32m    180\u001b[0m   )\n\u001b[0;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:284\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 284\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[0;32m    285\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[0;32m    286\u001b[0m )\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    289\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[0;32m    290\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    291\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:308\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m    304\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    305\u001b[0m       placeholder_context\n\u001b[0;32m    306\u001b[0m   )\n\u001b[1;32m--> 308\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    309\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    310\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mpython_function,\n\u001b[0;32m    311\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49margs,\n\u001b[0;32m    312\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49mkwargs,\n\u001b[0;32m    313\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    314\u001b[0m     func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    315\u001b[0m     arg_names\u001b[39m=\u001b[39;49mfunction_type_utils\u001b[39m.\u001b[39;49mto_arg_names(function_type),\n\u001b[0;32m    316\u001b[0m     create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    319\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    321\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m     42\u001b[0m       original_func,\n\u001b[0;32m     43\u001b[0m       args,\n\u001b[0;32m     44\u001b[0m       kwargs,\n\u001b[0;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     49\u001b[0m       ))\n\u001b[0;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileq4df7unb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1360\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1357\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m     )\n\u001b[0;32m   1359\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1360\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1361\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1362\u001b[0m     outputs,\n\u001b[0;32m   1363\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1364\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1365\u001b[0m )\n\u001b[0;32m   1366\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1679\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1675\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1678\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1679\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3269\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3267\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   3268\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 3269\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4067\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4065\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4066\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 4067\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1349\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1349\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1350\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1130\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1129\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m-> 1130\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m   1131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:544\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[1;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[39mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[39m  None\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    543\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_gradients(loss, var_list, tape)\n\u001b[1;32m--> 544\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1223\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_gradients_aggregation \u001b[39mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[0;32m   1222\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[1;32m-> 1223\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:652\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[0;32m    651\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m--> 652\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_apply_gradients(grads_and_vars)\n\u001b[0;32m    654\u001b[0m \u001b[39m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[39mfor\u001b[39;00m variable \u001b[39min\u001b[39;00m trainable_variables:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1253\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mesh \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_with_dtensor:\n\u001b[0;32m   1250\u001b[0m     \u001b[39m# Skip any usage of strategy logic for DTensor\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[1;32m-> 1253\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49minterim\u001b[39m.\u001b[39;49mmaybe_merge_call(\n\u001b[0;32m   1254\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply_gradients_fn,\n\u001b[0;32m   1255\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribution_strategy,\n\u001b[0;32m   1256\u001b[0m     grads_and_vars,\n\u001b[0;32m   1257\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[1;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[1;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribute_lib\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[0;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1345\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[1;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step(grad, var)\n\u001b[0;32m   1344\u001b[0m \u001b[39mfor\u001b[39;00m grad, var \u001b[39min\u001b[39;00m grads_and_vars:\n\u001b[1;32m-> 1345\u001b[0m     distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[0;32m   1346\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1349\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ema:\n\u001b[0;32m   1350\u001b[0m     _, var_list \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3013\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   3011\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[0;32m   3012\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3013\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_replica_ctx_update(\n\u001b[0;32m   3014\u001b[0m       var, fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, group\u001b[39m=\u001b[39;49mgroup)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2892\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[0;32m   2890\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39mgroup)\n\u001b[1;32m-> 2892\u001b[0m \u001b[39mreturn\u001b[39;00m replica_context\u001b[39m.\u001b[39;49mmerge_call(merge_fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3484\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3480\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   3482\u001b[0m merge_fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   3483\u001b[0m     merge_fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 3484\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_call(merge_fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3491\u001b[0m, in \u001b[0;36mReplicaContextBase._merge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3488\u001b[0m _push_per_thread_mode(  \u001b[39m# thread-local, so not needed with multiple threads\u001b[39;00m\n\u001b[0;32m   3489\u001b[0m     _CrossReplicaThreadMode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy))  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3490\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3491\u001b[0m   \u001b[39mreturn\u001b[39;00m merge_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   3492\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   3493\u001b[0m   _pop_per_thread_mode()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2890\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001b[1;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[1;32m-> 2890\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39;49mgroup)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3011\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   3008\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   3009\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   3010\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 3011\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[0;32m   3012\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[0;32m   3014\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[0;32m   4079\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[1;32m-> 4081\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(args), kwargs, group)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4087\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   4083\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[0;32m   4084\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[0;32m   4085\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[0;32m   4086\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[1;32m-> 4087\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   4088\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[0;32m   4089\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1342\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step_xla(grad, var, \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_key(var)))\n\u001b[0;32m   1341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_step(grad, var)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:241\u001b[0m, in \u001b[0;36m_BaseOptimizer._update_step\u001b[1;34m(self, gradient, variable)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_key(variable) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_dict:\n\u001b[0;32m    233\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe optimizer cannot recognize variable \u001b[39m\u001b[39m{\u001b[39;00mvariable\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis usually means you are trying to call the optimizer to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`tf.keras.optimizers.legacy.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_step(gradient, variable)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py:198\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[1;34m(self, gradient, variable)\u001b[0m\n\u001b[0;32m    195\u001b[0m     variable\u001b[39m.\u001b[39massign_sub((m \u001b[39m*\u001b[39m alpha) \u001b[39m/\u001b[39m (tf\u001b[39m.\u001b[39msqrt(v) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepsilon))\n\u001b[0;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[39m# Dense gradients.\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m     m\u001b[39m.\u001b[39massign_add((gradient \u001b[39m-\u001b[39;49m m) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta_1))\n\u001b[0;32m    199\u001b[0m     v\u001b[39m.\u001b[39massign_add((tf\u001b[39m.\u001b[39msquare(gradient) \u001b[39m-\u001b[39m v) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta_2))\n\u001b[0;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamsgrad:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1477\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1473\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1475\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[1;32m-> 1477\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1478\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1479\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1483\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:548\u001b[0m, in \u001b[0;36msubtract\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.subtract\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msubtract\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[0;32m    546\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    547\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msubtract\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 548\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49msub(x, y, name)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:13547\u001b[0m, in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  13545\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m  13546\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m> 13547\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m  13548\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mSub\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m  13549\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m  13550\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:778\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[0;32m    777\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[1;32m--> 778\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[0;32m    779\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[0;32m    780\u001b[0m                            input_types)\n\u001b[0;32m    781\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[0;32m    782\u001b[0m                            default_type_attr_map, attrs)\n\u001b[0;32m    783\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:551\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[1;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[0;32m    545\u001b[0m       values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    546\u001b[0m           values,\n\u001b[0;32m    547\u001b[0m           name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[0;32m    548\u001b[0m           as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[0;32m    549\u001b[0m           preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n\u001b[0;32m    550\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[0;32m    552\u001b[0m         values,\n\u001b[0;32m    553\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    554\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    555\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[0;32m    556\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[0;32m    557\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    558\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:698\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m    697\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[1;32m--> 698\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[0;32m    699\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[0;32m    700\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2315\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m-> 2315\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39;49m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1557\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1555\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_value()\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1556\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1557\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:632\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_value\n\u001b[0;32m    631\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mNone\u001b[39;00m, ignore_existing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 632\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:793\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    791\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    792\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 793\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    795\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    796\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    797\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    798\u001b[0m   record\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    799\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    800\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    801\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:783\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    782\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 783\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    785\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    786\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:603\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 603\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    604\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, resource\u001b[39m=\u001b[39;49mresource, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    605\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    791\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    792\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    794\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    795\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    797\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    798\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    800\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    804\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2657\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   2655\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 2657\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[0;32m   2658\u001b[0m       node_def,\n\u001b[0;32m   2659\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2660\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   2661\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   2662\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   2663\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   2664\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   2665\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   2666\u001b[0m   )\n\u001b[0;32m   2667\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   2668\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1161\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1158\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   1160\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1161\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   1162\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[0;32m   1163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:991\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m--> 991\u001b[0m   op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(c_graph,\n\u001b[0;32m    992\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m    993\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m    994\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m    995\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.Normalization()(input_node)\n",
    "output_node = ak.ImageAugmentation(horizontal_flip=False,vertical_flip=False)(output_node)\n",
    "output_node = ak.ResNetBlock()(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=10\n",
    ")\n",
    "clf.fit(X_train, y_train, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=clf.export_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: .\\auto_model\\best_pipeline : The system cannot find the file specified.\r\n; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m      2\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_pred, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mreshape(y_test\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\auto_model.py:451\u001b[0m, in \u001b[0;36mAutoModel.predict\u001b[1;34m(self, x, batch_size, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data_format((x, \u001b[39mNone\u001b[39;00m), predict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    450\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapt(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs, batch_size)\n\u001b[1;32m--> 451\u001b[0m pipeline \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49mget_best_pipeline()\n\u001b[0;32m    452\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtuner\u001b[39m.\u001b[39mget_best_model()\n\u001b[0;32m    453\u001b[0m dataset \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mtransform_x(dataset)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\engine\\tuner.py:67\u001b[0m, in \u001b[0;36mAutoTuner.get_best_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_best_pipeline\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m pipeline_module\u001b[39m.\u001b[39;49mload_pipeline(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_pipeline_path)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\pipeline.py:77\u001b[0m, in \u001b[0;36mload_pipeline\u001b[1;34m(filepath, custom_objects)\u001b[0m\n\u001b[0;32m     75\u001b[0m     custom_objects \u001b[39m=\u001b[39m {}\n\u001b[0;32m     76\u001b[0m \u001b[39mwith\u001b[39;00m keras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcustom_object_scope(custom_objects):\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m Pipeline\u001b[39m.\u001b[39mfrom_config(io_utils\u001b[39m.\u001b[39;49mload_json(filepath))\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autokeras\\utils\\io_utils.py:36\u001b[0m, in \u001b[0;36mload_json\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_json\u001b[39m(path):\n\u001b[0;32m     35\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> 36\u001b[0m         obj \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mloads(obj)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:116\u001b[0m, in \u001b[0;36mFileIO.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    105\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[39m  Starts reading from current position in file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m    string if in string (regular) mode.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preread_check()\n\u001b[0;32m    117\u001b[0m   \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    118\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_check_passed:\n\u001b[0;32m     75\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mPermissionDeniedError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                      \u001b[39m\"\u001b[39m\u001b[39mFile isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt open for reading\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_buf \u001b[39m=\u001b[39m _pywrap_file_io\u001b[39m.\u001b[39;49mBufferedInputStream(\n\u001b[0;32m     78\u001b[0m     compat\u001b[39m.\u001b[39;49mpath_to_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name), \u001b[39m1024\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m512\u001b[39;49m)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: .\\auto_model\\best_pipeline : The system cannot find the file specified.\r\n; No such file or directory"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "y_pred = y_pred.reshape(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = clf.tuner\n",
    "trial_ids = tuner.oracle.trials\n",
    "trials_hparams=[]\n",
    "score=[]\n",
    "for trial_id in trial_ids:\n",
    "    trial = clf.tuner.oracle.get_trial(trial_id)\n",
    "    trial.best_step\n",
    "    trial.metrics\n",
    "    hparams = trial.hyperparameters.values\n",
    "    score.append(trial.score)\n",
    "  # Append to list\n",
    "    trials_hparams.append(hparams)\n",
    "df = pd.DataFrame(trials_hparams)\n",
    "df['val_Loss']=score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image_block_1/block_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Group the DataFrame by 'image_block_1/block_type' and calculate the mean 'val_loss' within each group\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mimage_block_1/block_type\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mval_Loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()\n\u001b[0;32m      3\u001b[0m result\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   8250\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8252\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8253\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8254\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   8255\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   8256\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   8257\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   8258\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   8259\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   8260\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   8261\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   8262\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[0;32m    930\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    932\u001b[0m         obj,\n\u001b[0;32m    933\u001b[0m         keys,\n\u001b[0;32m    934\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    935\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    936\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    937\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    938\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    939\u001b[0m     )\n\u001b[0;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m    983\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 985\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    987\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    988\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image_block_1/block_type'"
     ]
    }
   ],
   "source": [
    "# Group the DataFrame by 'image_block_1/block_type' and calculate the mean 'val_loss' within each group\n",
    "result = df.groupby('image_block_1/block_type')['val_Loss'].mean()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_augmentation_1/translation_factor</th>\n",
       "      <th>image_augmentation_1/rotation_factor</th>\n",
       "      <th>image_augmentation_1/zoom_factor</th>\n",
       "      <th>image_augmentation_1/contrast_factor</th>\n",
       "      <th>res_net_block_1/pretrained</th>\n",
       "      <th>res_net_block_1/version</th>\n",
       "      <th>res_net_block_1/imagenet_size</th>\n",
       "      <th>classification_head_1/spatial_reduction_1/reduction_type</th>\n",
       "      <th>classification_head_1/dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>val_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>False</td>\n",
       "      <td>flatten</td>\n",
       "      <td>0.25</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32422.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>resnet152_v2</td>\n",
       "      <td>False</td>\n",
       "      <td>flatten</td>\n",
       "      <td>0.25</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_augmentation_1/translation_factor  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "\n",
       "   image_augmentation_1/rotation_factor  image_augmentation_1/zoom_factor  \\\n",
       "0                                   0.0                               0.0   \n",
       "1                                   0.0                               0.0   \n",
       "\n",
       "   image_augmentation_1/contrast_factor  res_net_block_1/pretrained  \\\n",
       "0                                   0.0                       False   \n",
       "1                                   0.0                       False   \n",
       "\n",
       "  res_net_block_1/version  res_net_block_1/imagenet_size  \\\n",
       "0                resnet50                          False   \n",
       "1            resnet152_v2                          False   \n",
       "\n",
       "  classification_head_1/spatial_reduction_1/reduction_type  \\\n",
       "0                                            flatten         \n",
       "1                                            flatten         \n",
       "\n",
       "   classification_head_1/dropout optimizer  learning_rate      val_Loss  \n",
       "0                           0.25      adam          0.001  32422.554688  \n",
       "1                           0.25      adam          0.001           NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
